import os
import json
import glob
import time
from openai import OpenAI
from dotenv import load_dotenv

# ==========================================
# 1. C·∫§U H√åNH & KH·ªûI T·∫†O
# ==========================================
load_dotenv(override=True)
api_key = os.getenv("OPENAI__API_KEY") 

if not api_key:
    print(" L·ªói: Ch∆∞a t√¨m th·∫•y API Key.")
    exit()

client = OpenAI(api_key=api_key)

# Folder ch·ª©a c√°c file JSON ƒë·ªông t√°c (Output c·ªßa b∆∞·ªõc tr∆∞·ªõc)
DATA_FOLDER = r"C:\Users\tabao\OneDrive\Desktop\Vitex\test_keypoint\moves_data"
STANDARDS_PATH = r"C:\Users\tabao\OneDrive\Desktop\Vitex\test_keypoint\dictionary_official.json"
REPORT_FOLDER = r"C:\Users\tabao\OneDrive\Desktop\Vitex\test_keypoint\reports" 

# T·∫°o folder b√°o c√°o n·∫øu ch∆∞a c√≥
if not os.path.exists(REPORT_FOLDER):
    os.makedirs(REPORT_FOLDER)

# ==========================================
# 2. H√ÄM TI·ªÜN √çCH
# ==========================================
def load_json(path):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f" L·ªói ƒë·ªçc file {path}: {e}")
        return None

def optimize_payload(frames_data):
    """
    N√©n d·ªØ li·ªáu: Ch·ªâ gi·ªØ timestamp v√† angles, l√†m tr√≤n s·ªë ƒë·ªÉ ti·∫øt ki·ªám token.
    """
    optimized = []
    for item in frames_data:
        compact = {
            "t": item.get("timestamp", 0),
            "a": {}
        }
        # Ch·ªâ l·∫•y angles, b·ªè keypoints
        if "angles" in item:
            for joint, angle in item["angles"].items():
                compact["a"][joint] = round(angle, 1)
        
        optimized.append(compact)
    return optimized

def analyze_single_file(file_path, standards_data):
    """G·ª≠i 1 file JSON l√™n GPT ƒë·ªÉ ph√¢n t√≠ch"""
    file_name = os.path.basename(file_path)
    print(f"\n ƒêang x·ª≠ l√Ω file: {file_name}...")
    
    user_data = load_json(file_path)
    if not user_data: return

    # L·∫•y th√¥ng tin metadata t·ª´ file JSON
    move_type = user_data.get("type", "Unknown")
    move_id = user_data.get("id", "0")
    raw_frames = user_data.get("frames", [])

    # T·ªëi ∆∞u d·ªØ li·ªáu frames
    compact_frames = optimize_payload(raw_frames)
    
    print(f"üì° G·ª≠i {len(compact_frames)} frames l√™n Server...")

    # --- PROMPT ---
    prompt = f"""
    B·∫°n l√† Hu·∫•n luy·ªán vi√™n Pickleball AI. H√£y ch·∫•m ƒëi·ªÉm k·ªπ thu·∫≠t cho pha b√≥ng n√†y.

    TH√îNG TIN PHA B√ìNG:
    - Lo·∫°i ƒë·ªông t√°c (AI nh·∫≠n di·ªán s∆° b·ªô): {move_type}
    - ID: {move_id}

    D·ªÆ LI·ªÜU TI√äU CHU·∫®N (Dictionary):
    {json.dumps(standards_data, ensure_ascii=False)}

    D·ªÆ LI·ªÜU TH·ª∞C T·∫æ (Time-series c·ªßa ng∆∞·ªùi ch∆°i):
    {json.dumps(compact_frames, ensure_ascii=False)}

    --- Y√äU C·∫¶U PH√ÇN T√çCH ---
    H√£y ki·ªÉm tra xem ng∆∞·ªùi ch∆°i c√≥ th·ª±c hi·ªán ƒê√öNG k·ªπ thu·∫≠t c·ªßa ƒë·ªông t√°c "{move_type}" hay kh√¥ng d·ª±a tr√™n Dictionary chu·∫©n.

    H√ÉY TR·∫¢ L·ªúI NG·∫ÆN G·ªåN, S√öC T√çCH THEO M·∫™U SAU:

    ##  PH√ÇN T√çCH PHA B√ìNG #{move_id} ({move_type})
    
    1. **ƒê·ªô ·ªïn ƒë·ªãnh:** (Nh·∫≠n x√©t v·ªÅ s·ª± m∆∞·ª£t m√† c·ªßa bi·ªÉu ƒë·ªì g√≥c)
    2. **L·ªói vi ph·∫°m (Timeline):**
       - **t=[Gi√¢y]:** [T√™n l·ªói] (G√≥c ƒëo ƒë∆∞·ª£c: ... | Chu·∫©n: ...).
       (Ch·ªâ li·ªát k√™ n·∫øu c√≥ l·ªói nghi√™m tr·ªçng v∆∞·ª£t ng∆∞·ª°ng)
    
    3. **K·∫øt lu·∫≠n:** [ƒê·∫†T / KH√îNG ƒê·∫†T]
    4. **L·ªùi khuy√™n:** [1 c√¢u s·ª≠a l·ªói]
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o", 
            messages=[
                {"role": "system", "content": "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu th·ªÉ thao kh·∫Øt khe."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        
        report_content = response.choices[0].message.content
        
        # In ra m√†n h√¨nh
        print("-" * 40)
        print(report_content)
        print("-" * 40)

        # L∆∞u ra file text
        report_filename = f"report_{file_name.replace('.json', '.txt')}"
        save_path = os.path.join(REPORT_FOLDER, report_filename)
        with open(save_path, "w", encoding="utf-8") as f:
            f.write(report_content)
        
        print(f" ƒê√£ l∆∞u b√°o c√°o: {save_path}")

    except Exception as e:
        print(f" L·ªói API khi x·ª≠ l√Ω file {file_name}: {e}")

# ==========================================
# 3. CH∆Ø∆†NG TR√åNH CH√çNH
# ==========================================
def main():
    print(" B·∫ÆT ƒê·∫¶U QU√âT FOLDER D·ªÆ LI·ªÜU...")
    
    # 1. Load ti√™u chu·∫©n
    standards_data = load_json(STANDARDS_PATH)
    if not standards_data:
        print(" Kh√¥ng t√¨m th·∫•y file Dictionary chu·∫©n.")
        return

    # 2. T√¨m t·∫•t c·∫£ file json b·∫Øt ƒë·∫ßu b·∫±ng 'action_'
    # (Do code tr∆∞·ªõc l∆∞u file d·∫°ng action_1_xxx.json)
    search_pattern = os.path.join(DATA_FOLDER, "action_*.json")
    json_files = glob.glob(search_pattern)

    if not json_files:
        print(f"Kh√¥ng t√¨m th·∫•y file JSON n√†o trong {DATA_FOLDER}")
        return

    print(f" T√¨m th·∫•y {len(json_files)} pha b√≥ng c·∫ßn ph√¢n t√≠ch.")

    # 3. L·∫∑p qua t·ª´ng file
    for file_path in json_files:
        analyze_single_file(file_path, standards_data)
        
        # Ngh·ªâ 1 ch√∫t ƒë·ªÉ tr√°nh rate limit (n·∫øu d√πng free tier)
        time.sleep(1) 

    print("\n HO√ÄN T·∫§T TO√ÄN B·ªò QU√Å TR√åNH PH√ÇN T√çCH!")
    print(f" Xem k·∫øt qu·∫£ t·∫°i folder: {REPORT_FOLDER}")

if __name__ == "__main__":
    main()